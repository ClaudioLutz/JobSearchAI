# JobSearchAI Source Tree Analysis

**Project:** JobSearchAI  
**Analysis Date:** 2025-10-15  
**Repository Type:** Monolith  
**Scan Level:** Deep

## Executive Summary

JobSearchAI is organized as a Flask monolith with clear separation of concerns through blueprints, models, utilities, and templates. The structure supports authentication, CV processing, job data acquisition, matching, and letter generation.

## Directory Structure

```
JobSearchAI/
â”œâ”€â”€ ğŸ“„ dashboard.py                    # ğŸš€ Main application entry point
â”œâ”€â”€ ğŸ“„ config.py                       # âš™ï¸  Centralized configuration
â”œâ”€â”€ ğŸ“„ init_db.py                      # ğŸ—„ï¸  Database initialization script
â”œâ”€â”€ ğŸ“„ requirements.txt                # ğŸ“¦ Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                       # ğŸ“– Project documentation
â”‚
â”œâ”€â”€ ğŸ“ blueprints/                     # ğŸ”µ Flask route blueprints (modular routes)
â”‚   â”œâ”€â”€ auth_routes.py                # ğŸ” Authentication routes (login, register, logout)
â”‚   â”œâ”€â”€ cv_routes.py                  # ğŸ“„ CV upload and processing routes
â”‚   â”œâ”€â”€ job_data_routes.py            # ğŸŒ Job scraping control routes
â”‚   â”œâ”€â”€ job_matching_routes.py        # ğŸ¯ Job matching execution routes
â”‚   â””â”€â”€ motivation_letter_routes.py   # âœ‰ï¸  Letter generation routes
â”‚
â”œâ”€â”€ ğŸ“ models/                         # ğŸ—„ï¸  Database models (SQLAlchemy)
â”‚   â”œâ”€â”€ __init__.py                   # Database and Flask-Login initialization
â”‚   â””â”€â”€ user.py                       # User model with authentication
â”‚
â”œâ”€â”€ ğŸ“ forms/                          # ğŸ“ WTForms form definitions
â”‚   â”œâ”€â”€ __init__.py                   # Forms package initialization
â”‚   â””â”€â”€ auth_forms.py                 # Login and registration forms
â”‚
â”œâ”€â”€ ğŸ“ templates/                      # ğŸ¨ Jinja2 HTML templates
â”‚   â”œâ”€â”€ index.html                    # Main dashboard interface
â”‚   â”œâ”€â”€ results.html                  # Job matching results view
â”‚   â”œâ”€â”€ cv_html_view.html             # CV display template
â”‚   â”œâ”€â”€ motivation_letter.html        # Letter generation form
â”‚   â”œâ”€â”€ job_data_view.html            # Scraped job data viewer
â”‚   â”œâ”€â”€ scraped_data_view.html        # Scraping results view
â”‚   â”œâ”€â”€ email_text_view.html          # Email text display
â”‚   â””â”€â”€ auth/                         # Authentication templates
â”‚       â”œâ”€â”€ base_auth.html            # Base auth page layout
â”‚       â”œâ”€â”€ login.html                # Login page
â”‚       â””â”€â”€ register.html             # Registration page
â”‚
â”œâ”€â”€ ğŸ“ static/                         # ğŸ¨ Static assets (CSS, JS, images)
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ styles.css                # Application styling (dark theme)
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ main.js                   # Client-side JavaScript
â”‚
â”œâ”€â”€ ğŸ“ utils/                          # ğŸ› ï¸  Utility modules
â”‚   â”œâ”€â”€ __init__.py                   # Utils package initialization
â”‚   â”œâ”€â”€ decorators.py                 # Error handling, retry, cache decorators
â”‚   â”œâ”€â”€ file_utils.py                 # File operation helpers
â”‚   â”œâ”€â”€ api_utils.py                  # OpenAI API wrappers
â”‚   â””â”€â”€ warning_utils.py              # Warning management utilities
â”‚
â”œâ”€â”€ ğŸ“ Documentation/                  # ğŸ“š Comprehensive component documentation
â”‚   â”œâ”€â”€ README.md                     # Documentation index
â”‚   â”œâ”€â”€ System.md                     # System architecture overview
â”‚   â”œâ”€â”€ Authentication_System.md      # Auth implementation details
â”‚   â”œâ”€â”€ Dashboard.md                  # Dashboard features and usage
â”‚   â”œâ”€â”€ CV_Processor.md               # CV processing pipeline
â”‚   â”œâ”€â”€ Job_Data_Acquisition.md       # Web scraping system
â”‚   â”œâ”€â”€ Job_Matcher.md                # Matching algorithm details
â”‚   â”œâ”€â”€ Motivation_Letter_Generator.md # Letter generation system
â”‚   â”œâ”€â”€ Word_Template_Generator.md    # DOCX generation
â”‚   â”œâ”€â”€ technical-decisions-template.md # Decision documentation template
â”‚   â”œâ”€â”€ Trafilatura_Migration_*.md    # Migration analysis documents
â”‚   â””â”€â”€ Stories/                      # User stories (if using agile)
â”‚
â”œâ”€â”€ ğŸ“ process_cv/                     # ğŸ“„ CV processing component
â”‚   â”œâ”€â”€ cv_processor.py               # Main CV processing logic
â”‚   â”œâ”€â”€ cv_to_html_converter.py       # CV â†’ HTML conversion
â”‚   â”œâ”€â”€ .env                          # CV processor environment vars
â”‚   â””â”€â”€ cv-data/
â”‚       â”œâ”€â”€ input/                    # ğŸ“¥ Uploaded CV files (PDF)
â”‚       â”œâ”€â”€ processed/                # âœ… Processed CV summaries (JSON)
â”‚       â””â”€â”€ html/                     # ğŸŒ CV HTML representations
â”‚
â”œâ”€â”€ ğŸ“ job-data-acquisition/           # ğŸŒ Job scraping service
â”‚   â”œâ”€â”€ app.py                        # Standalone scraper app
â”‚   â”œâ”€â”€ debug_scraper.py              # Debugging utility
â”‚   â”œâ”€â”€ settings.json                 # Scraper configuration
â”‚   â”œâ”€â”€ dependencies.txt              # Scraper-specific dependencies
â”‚   â”œâ”€â”€ README.md                     # Scraper documentation
â”‚   â”œâ”€â”€ Dockerfile                    # âš ï¸  DEPRECATED (Cloud deployment)
â”‚   â”œâ”€â”€ cloudbuild.yaml               # âš ï¸  DEPRECATED (CI/CD)
â”‚   â”œâ”€â”€ deploy-scraper-cloud-run.sh   # âš ï¸  DEPRECATED (Deployment)
â”‚   â”œâ”€â”€ data/                         # ğŸ’¾ Scraped job data (JSON files)
â”‚   â””â”€â”€ logs/                         # ğŸ“ Scraper log files
â”‚
â”œâ”€â”€ ğŸ“ motivation_letters/             # âœ‰ï¸  Generated motivation letters
â”‚   â”œâ”€â”€ template/                     # Word document templates
â”‚   â”‚   â”œâ”€â”€ motivation_letter_template.docx
â”‚   â”‚   â””â”€â”€ motivation_letter_template_mit_cv.docx
â”‚   â””â”€â”€ [generated files]/            # Generated DOCX, HTML, JSON files
â”‚
â”œâ”€â”€ ğŸ“ job_matches/                    # ğŸ¯ Job matching results
â”‚   â””â”€â”€ [match reports]/              # Match reports (MD, JSON)
â”‚
â”œâ”€â”€ ğŸ“ instance/                       # ğŸ—„ï¸  Database files (SQLite)
â”‚   â””â”€â”€ jobsearchai.db                # Local SQLite database
â”‚
â”œâ”€â”€ ğŸ“ logs/                           # ğŸ“ Application log files
â”‚   â”œâ”€â”€ dashboard.log
â”‚   â”œâ”€â”€ cv_processor.log
â”‚   â””â”€â”€ job_matcher.log
â”‚
â”œâ”€â”€ ğŸ“ memory/                         # ğŸ§  System memory/constitution
â”‚   â”œâ”€â”€ constitution.md               # System principles and rules
â”‚   â””â”€â”€ constitution_update_checklist.md
â”‚
â”œâ”€â”€ ğŸ“ bmad/                           # ğŸ¯ BMad Method integration
â”‚   â””â”€â”€ [BMad workflow files]
â”‚
â”œâ”€â”€ ğŸ“ docs/                           # ğŸ“Š Generated documentation (this folder)
â”‚   â”œâ”€â”€ bmm-workflow-status.md
â”‚   â”œâ”€â”€ project-scan-report.json
â”‚   â”œâ”€â”€ technology-stack.md
â”‚   â””â”€â”€ source-tree-analysis.md       # This file
â”‚
â”œâ”€â”€ ğŸ“ deprecated_20250427_211727/     # âš ï¸  Old code (archived)
â”‚   â””â”€â”€ [archived files]
â”‚
â”œâ”€â”€ ğŸ“ v4-backup/                      # âš ï¸  Backup of version 4
â”‚
â”œâ”€â”€ ğŸ“ web-bundles/                    # ğŸŒ Web-related bundles
â”‚
â”œâ”€â”€ ğŸ“ .github/                        # GitHub configuration
â”‚
â”œâ”€â”€ ğŸ“ .git/                           # Git repository data
â”‚
â”‚ # === Core Processing Scripts === #
â”œâ”€â”€ ğŸ“„ job_matcher.py                  # Job matching algorithm
â”œâ”€â”€ ğŸ“„ job_details_utils.py            # Job detail extraction
â”œâ”€â”€ ğŸ“„ motivation_letter_generator.py  # Letter generation logic
â”œâ”€â”€ ğŸ“„ letter_generation_utils.py      # Letter utilities
â”œâ”€â”€ ğŸ“„ word_template_generator.py      # DOCX file generation
â”œâ”€â”€ ğŸ“„ graph_scraper_utils.py          # Scraping utilities
â”œâ”€â”€ ğŸ“„ optimized_graph_scraper_utils.py # Optimized scraping
â”œâ”€â”€ ğŸ“„ headless_quality_analyzer.py    # Quality analysis tool
â”œâ”€â”€ ğŸ“„ fallback_quality_manager.py     # Quality management
â”‚
â”‚ # === Database & Migration === #
â”œâ”€â”€ ğŸ“„ migrate_add_admin_role.py       # Database migration script
â”œâ”€â”€ ğŸ“„ reset_admin_password.py         # Admin password reset
â”‚
â”‚ # === Deployment (DEPRECATED) === #
â”œâ”€â”€ ğŸ“„ Dockerfile                      # âš ï¸  DEPRECATED
â”œâ”€â”€ ğŸ“„ docker-compose.yml              # âš ï¸  DEPRECATED (if exists)
â”œâ”€â”€ ğŸ“„ cloudbuild.yaml                 # âš ï¸  DEPRECATED
â”œâ”€â”€ ğŸ“„ deploy-cloud-run.sh             # âš ï¸  DEPRECATED
â”œâ”€â”€ ğŸ“„ deploy-compute-engine.sh        # âš ï¸  DEPRECATED
â”œâ”€â”€ ğŸ“„ test-local-docker.sh            # âš ï¸  DEPRECATED
â”œâ”€â”€ ğŸ“„ .dockerignore                   # âš ï¸  DEPRECATED
â”‚
â”‚ # === Documentation & Analysis === #
â”œâ”€â”€ ğŸ“„ DEPLOYMENT_GUIDE.md             # âš ï¸  May be outdated (cloud-focused)
â”œâ”€â”€ ğŸ“„ CLOUD_RUN_DEPLOYMENT_FIXES.md   # âš ï¸  Cloud deployment issues
â”œâ”€â”€ ğŸ“„ HEADLESS_OPTIMIZATION_SUMMARY.md # Scraping optimization notes
â”œâ”€â”€ ğŸ“„ WEBSCRAPING_PROJECT_ANALYSIS.md # Web scraping analysis
â”œâ”€â”€ ğŸ“„ Documentation_update.md         # Documentation update notes
â”œâ”€â”€ ğŸ“„ monetization_plan.md            # Business planning
â”‚
â”‚ # === Configuration & Scripts === #
â”œâ”€â”€ ğŸ“„ .env                            # Root environment variables
â”œâ”€â”€ ğŸ“„ .gitignore                      # Git ignore rules
â”œâ”€â”€ ğŸ“„ .gitattributes                  # Git attributes
â”œâ”€â”€ ğŸ“„ set-api-key.sh                  # API key setup script
â”œâ”€â”€ ğŸ“„ mcp_requirements.txt            # MCP-specific requirements
â”œâ”€â”€ ğŸ“„ test_deployment_pipeline.py     # Deployment testing
â”‚
â”‚ # === Analysis & Quality === #
â”œâ”€â”€ ğŸ“„ headless_quality_analysis_*.json # Quality analysis results
â”œâ”€â”€ ğŸ“„ quality_report_*.json           # Quality reports
â”‚
â””â”€â”€ ğŸ“ __pycache__/                    # Python bytecode cache
```

## Critical Directories Explained

### `/blueprints/` - Flask Route Modules
**Purpose:** Modular organization of HTTP routes  
**Pattern:** Flask Blueprints for separation of concerns  
**Files:**
- `auth_routes.py` - User authentication (login/register/logout)
- `cv_routes.py` - CV upload and processing endpoints
- `job_data_routes.py` - Job scraping control
- `job_matching_routes.py` - Job matching execution
- `motivation_letter_routes.py` - Letter generation

**Integration:** All blueprints registered in `dashboard.py`

### `/models/` - Database Models
**Purpose:** SQLAlchemy ORM models  
**Key Files:**
- `user.py` - User model with password hashing, authentication
- `__init__.py` - Database initialization, Flask-Login setup

**Database:** SQLite (development) or PostgreSQL (production)

### `/templates/` - Jinja2 UI Templates
**Purpose:** Server-rendered HTML pages  
**Structure:**
- Root templates for main dashboard features
- `auth/` subfolder for authentication pages
- Dark theme styling
- Form-heavy interface for data entry

### `/static/` - Frontend Assets
**Purpose:** CSS, JavaScript, images  
**Contents:**
- `css/styles.css` - Application styling (dark theme)
- `js/main.js` - Client-side interactivity

### `/utils/` - Shared Utilities
**Purpose:** Reusable helper functions and decorators  
**Key Modules:**
- `decorators.py` - Error handling, retry logic, caching, timing
- `file_utils.py` - File operations with error handling
- `api_utils.py` - OpenAI API wrappers with retry/cache
- `warning_utils.py` - Warning management

### `/process_cv/` - CV Processing Pipeline
**Purpose:** CV upload, parsing, summarization  
**Flow:**
1. User uploads PDF â†’ `cv-data/input/`
2. `cv_processor.py` extracts text (PyMuPDF)
3. OpenAI summarizes â†’ `cv-data/processed/`
4. HTML view generated â†’ `cv-data/html/`

**Configuration:** `.env` file with OpenAI API key

### `/job-data-acquisition/` - Web Scraping Component
**Purpose:** Automated job listing scraping  
**Technology:** ScrapeGraphAI + Playwright  
**Structure:**
- `app.py` - Standalone scraper application
- `settings.json` - Scraper configuration
- `data/` - Scraped job listings (JSON)
- `logs/` - Scraping logs

**Note:** Originally designed as microservice, now integrated via dashboard

### `/motivation_letters/` - Letter Generation
**Purpose:** AI-generated personalized motivation letters  
**Flow:**
1. User triggers generation from dashboard
2. System combines: CV + Job description + AI
3. Generates: JSON structure â†’ HTML â†’ DOCX

**Templates:** Word document templates in `template/` subfolder

### `/Documentation/` - Comprehensive Docs
**Purpose:** Detailed component documentation  
**Quality:** Well-maintained, up-to-date  
**Coverage:**
- Architecture and system design
- Each component's functionality
- Implementation details
- Migration analyses

## Entry Points

### Primary Entry Point
**File:** `dashboard.py`  
**Function:** Starts Flask development server  
**Command:** `python dashboard.py`  
**Port:** 5000 (default)  
**Access:** `http://localhost:5000`

### Database Initialization
**File:** `init_db.py`  
**Purpose:** Create tables, seed admin user  
**Commands:**
```bash
python init_db.py                    # Initialize database
python init_db.py --create-admin     # Create admin user
python init_db.py --test-connection  # Test database
```

### Job Scraper (Standalone)
**File:** `job-data-acquisition/app.py`  
**Purpose:** Run scraper independently  
**Command:** `python job-data-acquisition/app.py`  
**Note:** Can also be triggered via dashboard

## Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Browser                         â”‚
â”‚                   http://localhost:5000                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Flask Dashboard                         â”‚
â”‚                    (dashboard.py)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Flask Blueprints                        â”‚  â”‚
â”‚  â”‚  â€¢ auth_routes    â€¢ cv_routes                        â”‚  â”‚
â”‚  â”‚  â€¢ job_data_routes â€¢ job_matching_routes            â”‚  â”‚
â”‚  â”‚  â€¢ motivation_letter_routes                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚             â”‚              â”‚                 â”‚
    â†“             â†“              â†“                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚SQLite â”‚  â”‚CV Processor â”‚  â”‚Job Scraperâ”‚   â”‚OpenAI API    â”‚
â”‚  DB   â”‚  â”‚  (PyMuPDF)  â”‚  â”‚(Playwright)â”‚   â”‚(GPT-4)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“             â†“              â†“                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Users  â”‚  â”‚CV Summaries â”‚  â”‚Job Data  â”‚   â”‚AI Generated  â”‚
â”‚Auth   â”‚  â”‚  (JSON)     â”‚  â”‚ (JSON)   â”‚   â”‚Content       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Integration Points

### Authentication Flow
1. User registers/logs in via `auth_routes.py`
2. Session managed by Flask-Login
3. All routes protected by `@login_required` decorator
4. User data stored in database (`models/user.py`)

### CV Processing Flow
1. Upload via `cv_routes.py` â†’ `process_cv/cv-data/input/`
2. `cv_processor.py` processes with PyMuPDF + OpenAI
3. Summary saved â†’ `process_cv/cv-data/processed/`
4. Dashboard displays results

### Job Scraping Flow
1. Trigger from dashboard (`job_data_routes.py`)
2. Calls `job-data-acquisition/app.py` logic
3. ScrapeGraphAI + Playwright scrapes jobs
4. Data saved â†’ `job-data-acquisition/data/`
5. Dashboard displays results

### Job Matching Flow
1. User selects CV and initiates match (`job_matching_routes.py`)
2. `job_matcher.py` loads CV + scraped jobs
3. OpenAI performs semantic matching
4. Results saved â†’ `job_matches/`
5. Dashboard displays matches

### Letter Generation Flow
1. User selects match and requests letter (`motivation_letter_routes.py`)
2. `motivation_letter_generator.py` combines CV + job + AI
3. JSON structure â†’ HTML â†’ DOCX (via `word_template_generator.py`)
4. Files saved â†’ `motivation_letters/`
5. User downloads results

## Configuration Management

### Centralized Config
**File:** `config.py`  
**Purpose:** Single source of truth for all settings  
**Contains:**
- File paths
- API endpoints
- Default parameters
- Environment variable loading

### Environment Variables
**Locations:**
- `.env` (root) - General settings
- `process_cv/.env` - CV processor settings

**Required Variables:**
- `OPENAI_API_KEY` - OpenAI API authentication
- `SECRET_KEY` - Flask session encryption
- `DATABASE_URL` - PostgreSQL connection (optional)

## Deprecated/Unused Files

### Cloud Deployment (DEPRECATED)
These files were part of the Google Cloud deployment plan:
- `Dockerfile`
- `cloudbuild.yaml`
- `deploy-cloud-run.sh`
- `deploy-compute-engine.sh`
- `test-local-docker.sh`
- `.dockerignore`
- `DEPLOYMENT_GUIDE.md` (partially outdated)
- `CLOUD_RUN_DEPLOYMENT_FIXES.md`

**Status:** No longer needed (local deployment only)  
**Action:** Can be safely ignored or archived

### Archived Code
- `deprecated_20250427_211727/` - Old code snapshots
- `v4-backup/` - Previous version backup

## Development Workflow

### Local Development
1. Clone repository
2. Install dependencies: `pip install -r requirements.txt`
3. Configure environment: Create `.env` files
4. Initialize database: `python init_db.py`
5. Run application: `python dashboard.py`
6. Access: `http://localhost:5000`

### Adding New Features
1. Create blueprint in `blueprints/` (if new route group)
2. Add templates in `templates/`
3. Update models if database changes needed
4. Add utilities to `utils/` if reusable
5. Document in `Documentation/`

### Testing Approach
- Manual testing via web dashboard
- Logging to track errors (`logs/` directory)
- No automated test suite currently

## Code Quality Patterns

### Error Handling
- Custom decorators in `utils/decorators.py`
- Try-except blocks with logging
- User-friendly error messages in UI

### API Usage
- Wrappers in `utils/api_utils.py`
- Retry logic for transient failures
- Caching for repeated calls
- Rate limit awareness

### File Operations
- Helpers in `utils/file_utils.py`
- Consistent error handling
- Automatic directory creation
- Path validation

## Summary

JobSearchAI follows a clean monolithic architecture with:

**Strengths:**
- âœ… Clear separation of concerns (blueprints, models, utils)
- âœ… Comprehensive existing documentation
- âœ… Centralized configuration management
- âœ… Reusable utility functions
- âœ… Production-ready authentication
- âœ… Well-organized file structure

**Areas for Enhancement:**
- ğŸ”§ Add automated testing
- ğŸ”§ Clean up deprecated deployment files
- ğŸ”§ Add API rate limiting
- ğŸ”§ Implement background job processing
- ğŸ”§ Add export/import functionality

**Active Development Areas:**
- All blueprint routes
- AI processing components
- Web scraping system
- Document generation

The structure supports both current single-user local deployment and potential future enhancements (multi-user, cloud deployment, microservices extraction) without major refactoring.
